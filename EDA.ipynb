{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title: [Your Project Name]\n",
    "### Subtitle: [Optional: Brief Description]\n",
    "\n",
    "**Author:** [Viet Anh Dong]  \n",
    "**Date:** [17 December 2024]  \n",
    "**Dataset:** [Dataset Source or Description]\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "- **Objective:** predict loan approval status of a person base\n",
    "- **Dataset Description:** Provide an overview of the dataset (e.g., number of records, columns, source).\n",
    "- **Key Questions:** List the questions you want to answer or the problems you're solving.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Project Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_cleaning import *\n",
    "from src.EDA import *\n",
    "from IPython.display import Markdown\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Data and Remove NaN values\n",
    "After this step we have an analyse dataset without the present of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data, analyse_data = load_and_remove_nan(file_path='/mnt/d/Beta/data/raw_loan_data.csv');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "**Objectives** Uncover patterns, relationships, and insights in the data.\n",
    "### 3.1. Detect Outliers\n",
    "Identify unusual values that may impact analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_dataframe(analyse_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen from the plot, the dataset presents outliers and unusual values in the set. for example, there are some people that is recored as more than 100 years while the rest of sample range between 20 to 40 years old. it is similar to year of employment experience. Thus, we have envidence that there is unsual values presenting in this data set. As we have more than 400K of samples and the unusual values according to the plot is about less than 1% of sample size. Therefore, the safetest, solution in this case is to remove any sample that have NaN present. Follow helper function will do the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_data_no_nan = remove_outliers(analyse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(analyse_data_no_nan, target_feature='loan_status', jitter_width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Multicolinearity Detection\n",
    "#### 3.2.2. Correlation Matrix\n",
    "The correlation matrix is a table that shows the correlation between each pair of variables in a dataset. It is a square matrix where the entry in the i-th row and j-th column is the correlation between the i-th and j-th variables. The correlation matrix is used to detect multicolinearity in a dataset. Fristly, we need to calculate the correlation matrix of the dataset.\n",
    "As the dataset contains 5 variables that have datat type of objects including 2 nominal (non-ordinal) variables and 3 ordinal variables. Thus, we use OneHotEncoder and LabelEncoder to encode the data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_data_no_nan = ordinal_encode_column_inplace(analyse_data_no_nan, columns_to_encode=['person_gender', 'person_education', 'previous_loan_defaults_on_file'])\n",
    "analyse_data_no_nan = ordinal_encode_column_inplace(analyse_data_no_nan, columns_to_encode=['person_home_ownership', 'loan_intent'])\n",
    "# in this project, I also create One-Hot-Encode function to encode categorical variables\n",
    "#  that do not hierachical properties such loan_intent\n",
    "# but it create perfect mulicolinearity issues because of the high number of categories \n",
    "# so I use only ordinal encoding for categorical variables with hierachical properties to avoid this issue\n",
    "# one-hot-encode should use with binary features\n",
    "# more than two features may cause perfect multicolinearity issues.\n",
    "# if binary should use option drop first category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Using Variance Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_report = calculate_vif(analyse_data_no_nan.drop(columns='loan_status'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Relationship Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate dependent and independent variables\n",
    "X = analyse_data_no_nan.drop(columns='loan_status')\n",
    "y = analyse_data_no_nan['loan_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
