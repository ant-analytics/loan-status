{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "The main objective of this showcase project is to build a predictive model to predict (i) loan status, approve/reject, for potential clients; (ii) credit score variable based on individual and loan-related attributes. <br>\n",
    "The project uses the [Loan Approval Classification Dataset on Kaggle](https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data/data?select=loan_data.csv). This report presents steps to achieve this objective. The source code of this project is available at [Github](https://github.com/ant-analytics/Beta.git)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understand Data\n",
    "Import required packages and process to load data then display the first few rows of the dataset to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src') # ensure the src folder in the python path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# project packages\n",
    "from src.data_loader import load_data\n",
    "from src.data_eda import *\n",
    "from src.model_train import *\n",
    "from src.hpmodel import *\n",
    "\n",
    "# set project random state\n",
    "random_state = 42\n",
    "\n",
    "# Data loader\n",
    "raw_data_path = './data/raw_loan_data.csv'\n",
    "metadata_path = './data/metadata.txt'\n",
    "raw_data, num_features, cat_features, metadata = load_data(raw_data_path, metadata_path)\n",
    "metadata.sort_values(by='Type').reset_index(drop=True)\n",
    "\n",
    "original_indices = raw_data.index # Keep the original indices for later use\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display some key information about features in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['na_count'] = raw_data.isna().sum().values\n",
    "metadata.sort_values(by='Type').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14 features in the dataset including 5 qualitative features and 9 quantitative features. The target variable is `loan_Status` which is a qualitative feature but already coded as integer; the targer 'credit_score' is quantitative feature. This finding suggests that features encoding is required for qualitative features. Additionally, there is no missing values in the dataset <br>\n",
    "Let's check key information about quantitative features in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_data(raw_data[num_features]).round(2).rename(columns=metadata.set_index('Feature')['Description'].to_dict()).T.sort_values(by='max', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from statistic summary, the range of values for each feature is different. For example the range of income is from 80K to 7000K while the range of age is from 20 to 144. This finding sugests that the features need to be rescaled before serving as input to the model. <br>\n",
    "Addtionally, there are unusual values in the dataset such as the age of a person is 144 or year of employment experiece is 125. These values are not practical and need to be treated as outliers. <br>.\n",
    "Let's display a dashboard to have an over view of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('plots/eda_dashboard.png')\n",
    "\n",
    "# display image\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # hide axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dashboard, we can see that number of reject and approve loand are imbalanced. Therefore, we should use stratified sampling methods to ensure that train, validation and test set maintain this propotion. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "In this project, I will divide the dataset to train, validation and test set with propotion of 50-30-20, respectively. The source code for split function is available at [Github](https://github.com/ant-analytics/Beta.git).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "from src.data_preprocessing import split_data, preprocess_data, transform_features\n",
    "X_train, X_val, X_test, y_train_loan_status, y_val_loan_status, y_test_loan_status, y_train_score, y_val_score, y_test_score = split_data(raw_data)\n",
    "print(f\"Train data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, outliers with respect to person age and  are presented in the dataset. These data points should be labeled and remove from the set properly. In this project, I use Isolation Forest method to detect ouliers. Details about isolation forest can be found at [Wikipedia](https://en.wikipedia.org/wiki/Isolation_forest). To do that, I will train a outliers detector on train set, use person age, year of employment experience and length of credit history in years as features to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "outlier_features = ['person_age', 'person_emp_exp', 'cb_person_cred_hist_length']\n",
    "outlier_detector = IsolationForest(contamination=0.009, random_state=random_state)\n",
    "X_train['outliers'] = outlier_detector.fit_predict(X_train[outlier_features])\n",
    "indices_to_remove = X_train[X_train['outliers'] == -1].index # Get the indices of the outliers\n",
    "\n",
    "# Plot box plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 12), sharex=True)\n",
    "for i, feature in enumerate(X_train[['person_age', 'person_emp_exp', 'cb_person_cred_hist_length']].columns):\n",
    "    description = metadata.loc[metadata['Feature'] == feature, 'Description'].values[0]\n",
    "    ax = axs[i]\n",
    "    boxplot = ax.boxplot([X_train[X_train['outliers'] == 1][feature], X_train[X_train['outliers'] == -1][feature]], \n",
    "                         labels=['Inliers', 'Outliers'], vert=False)\n",
    "    ax.set_title(f'Box Plot of {description}', fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel(description)\n",
    "    ax.set_ylabel(f'Outliers Detection')\n",
    "    \n",
    "    # # Add mean annotation for inliers\n",
    "    # mean_inliers = boxplot['means'][0].get_xdata()[0]\n",
    "    # ax.annotate(f'Mean: {mean_inliers:.2f}', xy=(mean_inliers, 1), xytext=(mean_inliers + 0.5, 1.1),\n",
    "    #             horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # # Add mean annotation for outliers\n",
    "    # mean_outliers = boxplot['means'][1].get_xdata()[0]\n",
    "    # ax.annotate(f'Mean: {mean_outliers:.2f}', xy=(mean_outliers, 2), xytext=(mean_outliers + 1, 2.1),\n",
    "    #             horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # Draw vertical line through min values\n",
    "    # min_inliers = boxplot['whiskers'][0].get_xdata()[0]\n",
    "    min_outliers = boxplot['caps'][2].get_xdata()[0]\n",
    "    # ax.axvline(min_inliers, color='r', linestyle='--', label='Min Inliers')\n",
    "    ax.axvline(min_outliers, color='r', linestyle='--', label='Min Outliers')\n",
    "    \n",
    "    # Add tick label for red line\n",
    "    # ax.annotate(f'{min_inliers:.2f}', xy=(min_inliers, 0.5), xytext=(min_inliers, 0.5),\n",
    "    #             color='red', horizontalalignment='center', verticalalignment='center')\n",
    "    # ax.annotate(f'{min_outliers:.2f}', xy=(min_outliers, 1.5), xytext=(min_outliers, 1.5),\n",
    "    #             color='red', horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot, the outlier dectector are reasonable to detect outlier in the dataset. We will use this detector to remove outliers from the validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "X_train.drop(index=indices_to_remove, columns='outliers', inplace=True)\n",
    "y_train_loan_status.drop(labels=indices_to_remove, inplace=True)\n",
    "y_train_score.drop(labels=indices_to_remove, inplace=True)\n",
    "\n",
    "# Remove outliers from validation set\n",
    "X_val['outliers'] = outlier_detector.predict(X_val[outlier_features])\n",
    "val_indices_to_remove = X_val[X_val['outliers'] == -1].index\n",
    "X_val.drop(index=val_indices_to_remove, columns='outliers', inplace=True)\n",
    "y_val_loan_status.drop(labels=val_indices_to_remove, inplace=True)\n",
    "y_val_score.drop(labels=val_indices_to_remove, inplace=True)\n",
    "\n",
    "# Remove outliers from test set\n",
    "X_test['outliers'] = outlier_detector.predict(X_test[outlier_features])\n",
    "test_indices_to_remove = X_test[X_test['outliers'] == -1].index\n",
    "X_test.drop(index=test_indices_to_remove, columns='outliers', inplace=True)\n",
    "y_test_loan_status.drop(labels=test_indices_to_remove, inplace=True)\n",
    "y_test_score.drop(labels=test_indices_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to preprocess data. Two tasks need to be done: (i) encode categorical variables and (ii) scale numerical variables. For the first task, I will use ordinal endcode method to encode categorical variables. For the second task, I will use standard scaler to scale numerical variables. The source code for these tasks is available at [Github](https://github.com/ant-analytics/Beta.git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "X_train_transform, X_val_transform, X_test_transform, y_train_score_transform, y_val_score_transform, y_test_score_transform, col_transformer, y_scaler = preprocess_data(\n",
    "    X_train, X_val, X_test, y_train_score, y_val_score, y_test_score, num_features, cat_features)\n",
    "\n",
    "# keep track features for interpretate\n",
    "transform_features = transform_features(col_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot features after transform\n",
    "fig, axs = plt.subplots(4, 3, figsize=(24, 18), sharex=True)\n",
    "for i, feature in enumerate(transform_features):\n",
    "    ax = axs[i//3, i%3]\n",
    "    boxplot = ax.boxplot(X_test_transform[:, i], showfliers=True, vert=False, showmeans=True, meanline=True)\n",
    "    description = metadata.loc[metadata['Feature'] == feature, 'Description'].values[0]\n",
    "    ax.set_title(f'Box Plot of {description}', fontweight='bold', fontsize=14)\n",
    "    ax.yaxis.set_ticklabels([])  # Set y-tick labels off\n",
    "    \n",
    "    # Add mean annotation\n",
    "    # mean = boxplot['means'][0].get_xdata()[0]\n",
    "    # ax.annotate(f'Mean: {mean:.2f}', xy=(mean, 1), xytext=(mean, 1.1),\n",
    "    #             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "    #             horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # Add x-axis label\n",
    "    ax.set_xlabel('Value')\n",
    "    \n",
    "    # Add legend for mean and median lines\n",
    "    ax.legend([boxplot['means'][0], boxplot['medians'][0]], ['Mean', 'Median'], loc='upper right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development and Training\n",
    "The purpose of this project is to predict loan status and credit score. These outputs are different in nature. Loan status is a binary output coded as 1 for approve and 0 for reject. Meanwhile, credit score is a continuous variable. Thus, our problems are classification and regression problems. The predictive models use the same set of input data. A popular choice for this type of problem is to develop two separate models for each problem. However, in this project, I will use a single neural network model to predict both loan status and credit score.<br>\n",
    "The next step is to build the model architecture, set up hyperparameters, and train the network. A common approach to developing the network is to start with a reasonable architecture and hyperparameters, then tune them to improve the model performance. But, in this project, I will do it in reverse order. I will start with tuning hyperparameters, then choose the \"best\" model architecture. From this point, I will train the model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "tuner_log_dir = f\"logs/tuner/tuner_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "tuner_save_check_point = f'save_tuner/checkpoint_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.keras'\n",
    "\n",
    "# Create TensorBoard callback\n",
    "tuner_tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=tuner_log_dir,  \n",
    "    histogram_freq=1,\n",
    "    profile_batch='500,520'\n",
    ")\n",
    "\n",
    "tuner_early_stop_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_output_status_accuracy',\n",
    "    patience=3,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "tuner_check_point = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_tuner.keras',\n",
    "    monitor='val_output_status_accuracy',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "tuner_callbacks = [tuner_tensorboard_callback, tuner_early_stop_callback, tuner_check_point]\n",
    " \n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=build_hyper_model,\n",
    "    objective=[\n",
    "        keras_tuner.Objective('val_output_status_accuracy', direction='max'),\n",
    "        keras_tuner.Objective('val_output_score_mean_squared_error', direction='min')\n",
    "    ],\n",
    "    max_trials=50,\n",
    "    directory=tuner_log_dir,\n",
    "    project_name='loan_default_prediction',\n",
    "    overwrite=True\n",
    ")\n",
    "# Tuning hyperparameters\n",
    "tuner.search(\n",
    "    X_train_transform, y=[y_train_loan_status, y_train_score_transform],\n",
    "    validation_data=(X_val_transform, [y_val_loan_status, y_val_score_transform]), epochs=50,\n",
    "    callbacks=tuner_callbacks\n",
    ")\n",
    "\n",
    "# Retrieve and save the top 10 best models\n",
    "save_dir = 'save_tuner/top_best/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "best_models = tuner.get_best_models(num_models=10)\n",
    "for i, model in enumerate(best_models):\n",
    "    model.save(f'save_tuner/top_best/{i+1}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.keras')\n",
    "\n",
    "save_worst = 'save_tuners/top_worst/'\n",
    "os.makedirs(save_worst, exist_ok=True)\n",
    "worst_models = tuner.get_best_models(num_models=-10)\n",
    "for i, model in enumerate(worst_models):\n",
    "    model.save(f'save_models/top_worst/{i+1}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning, choose the best model then plot model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "plot_model(best_model, to_file='plots/best_model.png', show_shapes=True, show_layer_names=True, show_layer_activations=True, show_trainable=True, show_dtype=True, dpi=96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to train the model. The training process will take a while. After training, we will evaluate the model performance on the validation set. The evaluation metrics for classification and regression problems are accuracy and mean squared error, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calbacks for fit model\n",
    "fit_log_dir = f\"logs/fits/fit_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "fit_save_check_point = f'save_fits/checkpoint_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.keras'\n",
    "\n",
    "# Create TensorBoard callback\n",
    "fit_tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=fit_log_dir,  \n",
    "    histogram_freq=1,\n",
    "    profile_batch='500,520'\n",
    ")\n",
    "\n",
    "fit_early_stop_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_output_status_accuracy',\n",
    "    patience=3,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "fit_check_point = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=fit_save_check_point,\n",
    "    monitor='val_output_status_accuracy',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "fit_callbacks = [fit_tensorboard_callback, fit_early_stop_callback, fit_check_point]\n",
    "\n",
    "#  fit the best model\n",
    "history = best_model.fit(\n",
    "    X_train_transform, [y_train_loan_status, y_train_score_transform],\n",
    "    validation_data=(X_val_transform, [y_val_loan_status, y_val_score_transform]),\n",
    "    epochs=100, callbacks=fit_callbacks, shuffle=True\n",
    ")\n",
    "\n",
    "# model evaluation\n",
    "evaluation = best_model.evaluate(X_test_transform, [y_test_loan_status, y_test_score_transform], return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project has built a a predictive model to predict loan status and credit score base of 45K sample dataset. The model use IsolationForest to detect outliers and use a single neural network model to predict both loan status and credit score. However, this project stil need improvement in the following aspects: (i) a multi criteria should be use to monitor hypertuning process; (ii) should develop a different models to comparison./. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
